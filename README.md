# fitETL: pushing updates from production to a data warehouse
As an Insight Data Engineering Fellow, I worked on a consulting project for a health science company. The project involved developing a batch processing pipeline for pushing updates from production to a data warehouse for later analysis.

## Motivation
The company is collecting large amounts of data from multiple sources. Currently, the data is stored in Postgres tables on Amazon RDS but for more efficient analyses, the company wants to move its data to Amazon Redshift. 

## Pipeline
![alt text](https://github.com/seunghalee/fitETL/blob/master/img/pipeline.png "ETL Pipeline")
